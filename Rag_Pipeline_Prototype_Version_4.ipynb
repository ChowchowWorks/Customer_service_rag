{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNsXePUlFfL5NvBe7BrzKgY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChowchowWorks/Customer_service_rag/blob/main/Rag_Pipeline_Prototype_Version_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1: Setting up the Environment"
      ],
      "metadata": {
        "id": "BDlV5Vqi9hcq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "uI6LsJR7aFJs"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "!pip install langchain_community langchain chromadb transformers sentence-transformers\n",
        "!pip install -U langchain-huggingface\n",
        "\n",
        "!pip install pypdf\n",
        "\n",
        "os.environ['LANGCHAIN_API_KEY'] = \"API_KEY\"\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = \"API_KEY\"\n",
        "os.environ['USER_AGENT'] = 'MyColabApp/1.0 (Python/3.9; GoogleColab)'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: Loading Documents"
      ],
      "metadata": {
        "id": "F6gCPqCz-O02"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) Loading documents into a global variable"
      ],
      "metadata": {
        "id": "K0axoXMo-Y0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFDirectoryLoader\n",
        "\n",
        "# For the purpose of testing, this version uses a pdf loader\n",
        "loader = PyPDFDirectoryLoader(\"/content/RAG tester\")\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "0RJuj3tV-VZG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Splitting documents into manageable chunks"
      ],
      "metadata": {
        "id": "ShXjKXYB-qqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 100) # These are hyperparameters, can attempt tuning this using bayesian optimisation in the future\n",
        "texts = splitter.split_documents(documents)"
      ],
      "metadata": {
        "id": "-FxvVo0t-0U2"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3: Indexing"
      ],
      "metadata": {
        "id": "uDybpczf_jEC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) Embedding Text Chunks into the vector store"
      ],
      "metadata": {
        "id": "UJapD5z-_oeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectorstore = Chroma.from_documents(texts, embeddings)"
      ],
      "metadata": {
        "id": "G_QTAEKD_m55"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Declaring the number of chunks used in producing response"
      ],
      "metadata": {
        "id": "EfXTh-EbAIfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k = 5\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": k})"
      ],
      "metadata": {
        "id": "Hon-Rg7ZAP52"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 4: Setting up the Generator"
      ],
      "metadata": {
        "id": "Xu7TPr4GFyyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import InferenceClient\n",
        "client = InferenceClient(model=\"mistralai/Mistral-7B-Instruct-v0.3\", token= \"API_KEY\")\n",
        "\n",
        "from langchain_core.runnables import Runnable\n",
        "\n",
        "class HuggingFaceChatRunnable(Runnable):\n",
        "    def __init__(self, client, prompt_template, temperature, max_tokens):\n",
        "        self.client = client\n",
        "        self.prompt_template = prompt_template\n",
        "        self.temperature = temperature\n",
        "        self.max_tokens = max_tokens\n",
        "\n",
        "    def invoke(self, inputs: dict, config: dict = None) -> str:\n",
        "        prompt_str = self.prompt_template.format(**inputs)\n",
        "\n",
        "        response = self.client.chat_completion(\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": prompt_str}\n",
        "            ],\n",
        "            temperature=self.temperature,\n",
        "            max_tokens=self.max_tokens\n",
        "        )\n",
        "        return response.choices[0].message[\"content\"]"
      ],
      "metadata": {
        "id": "lpmMjgJEF2gb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 5: Routing Prompts"
      ],
      "metadata": {
        "id": "dyLsXvkUAUpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) Produce some fewshot examples to incorporate into routing prompt"
      ],
      "metadata": {
        "id": "upDsjwn-AYLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.prompts import FewShotChatMessagePromptTemplate\n",
        "\n",
        "# Some fewshot examples\n",
        "examples =[\n",
        "    {\n",
        "        \"input\": \"What is creatine?\",\n",
        "        \"output\": \"DEFINE\",\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Why do athletes take protein after workouts?\",\n",
        "        \"output\": \"EXPLAIN\",\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"How do I calculate my calorie needs?\",\n",
        "        \"output\": \"PROCEDURE\",\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Should I take whey or casein protein?\",\n",
        "        \"output\": \"COMPARISON\",\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "example_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"ai\", \"{output}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "few_shot_examples = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_prompt,\n",
        "    examples=examples,\n",
        ")\n"
      ],
      "metadata": {
        "id": "ZL8N9NucAbo_"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) Setting up the intent prompt"
      ],
      "metadata": {
        "id": "jMHwyRLCB_wV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intent_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"You are an intent classifier for the field of interest in the query.\n",
        "Given a question, classify it into one of the following intents:\n",
        "- DEFINE: Asking for a definition or description\n",
        "- EXPLAIN: Asking for reasoning or why something is the case\n",
        "- PROCEDURE: Asking for how-to or steps\n",
        "- ADVICE: Asking for personalized or practical suggestions\n",
        "- COMPARISON: Asking to compare options\n",
        "- GENERAL: Anything else\n",
        "Return only the intent, nothing else.\n",
        "Here are a few examples:\"\"\",\n",
        "        ),\n",
        "        # few shot examples\n",
        "        few_shot_examples,\n",
        "        # New question\n",
        "        (\"user\", \"{question}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "0Qy2rB7hCCQD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Set up routing"
      ],
      "metadata": {
        "id": "VV02vv2HGFB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "router = HuggingFaceChatRunnable(client, intent_prompt, 0.0, 10)"
      ],
      "metadata": {
        "id": "q4972BN9GEsh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 6: Step Back Translation"
      ],
      "metadata": {
        "id": "2nUht4lFJVV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) Step-back prompt"
      ],
      "metadata": {
        "id": "TZbzsFQuJkr7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This are examples that shows the LLM what it is achieving through stepback\n",
        "\n",
        "examples = [\n",
        "    {\n",
        "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
        "        \"output\": \"what can the members of The Police do?\",\n",
        "    },\n",
        "    {\n",
        "        \"input\": \"Jan Sindel’s was born in what country?\",\n",
        "        \"output\": \"what is Jan Sindel’s personal history?\",\n",
        "    },\n",
        "]\n",
        "\n",
        "# Now translate this into an example_prompt\n",
        "example_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\"human\", \"{input}\"),\n",
        "        (\"ai\", \"{output}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "few_shot = FewShotChatMessagePromptTemplate(\n",
        "    example_prompt=example_prompt,\n",
        "    examples=examples,\n",
        ")\n",
        "\n",
        "step_back_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"You are an expert at world knowledge. Your task is to step back and paraphrase a question to a more generic step-back question, which is easier to answer. Here are a few examples:\"\"\",\n",
        "        ),\n",
        "        # Few shot examples\n",
        "        few_shot,\n",
        "        # New question\n",
        "        (\"user\", \"Intent: {intent}\\nQuestion: {question}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "QaI6uYPoJZhL"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Set up Step Back"
      ],
      "metadata": {
        "id": "6Fw5-YiqMXEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stepback = HuggingFaceChatRunnable(client, step_back_prompt, 0.0, 1024)"
      ],
      "metadata": {
        "id": "CTgqGM3zMWQJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 7: Routing Chains"
      ],
      "metadata": {
        "id": "v9E2HlrVMlus"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(a) Chains"
      ],
      "metadata": {
        "id": "8DBXcG09NeNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define prompt\n",
        "defineprompt = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
        "You are responding to a query with the intent: DEFINE.\n",
        "Your answer should be:\n",
        "- Comprehensive, but concise (1–3 sentences max)\n",
        "- Factually correct and aligned with the provided context\n",
        "- Free of speculation, advice, or subjective judgment\n",
        "- Focused only on essential information—no unnecessary background or examples unless they resolve ambiguity\n",
        "- Adjusted for multiple meanings if applicable\n",
        "- Written in terminology appropriate to the user's domain or field\n",
        "\n",
        "\n",
        "# {normal_context}\n",
        "# {step_back_context}\n",
        "\n",
        "# Original Question: {question}\n",
        "# Answer:\"\"\"\n",
        "\n",
        "#explain prompt\n",
        "explainprompt = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
        "You are responding to a query with the intent: EXPLAIN.\n",
        "Your answer should be:\n",
        "- Clear and logically structured\n",
        "- Focused on cause, reasoning, background, or significance\n",
        "- Factually correct and aligned with the provided context\n",
        "- Neutral in tone—avoid persuasion, speculation, or personal opinions\n",
        "- Examples are welcome from the context provided, if it helps to improve understanding.\n",
        "\n",
        "# {normal_context}\n",
        "# {step_back_context}\n",
        "\n",
        "# Original Question: {question}\n",
        "# Answer:\"\"\"\n",
        "\n",
        "#procedure prompt\n",
        "procedureprompt = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
        "You are responding to a query with the intent: PROCEDURE.\n",
        "Your answer should be:\n",
        "- Structured as a clear, ordered list of steps (e.g., 1, 2, 3...)\n",
        "- Focused on how-to instructions or best-practice sequences\n",
        "- Specific, practical, and applicable to the user’s likely context\n",
        "- Factually accurate and based on reliable knowledge\n",
        "- Aligned with the provided context; ignore context if irrelevant\n",
        "\n",
        "# {normal_context}\n",
        "# {step_back_context}\n",
        "\n",
        "# Original Question: {question}\n",
        "# Answer:\n",
        "1.\n",
        "2.\n",
        "3.\"\"\"\n",
        "\n",
        "#advice prompt\n",
        "adviceprompt = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
        "You are responding to a query with the intent: ADVICE.\n",
        "Your answer should be:\n",
        "- Actionable and practical, tailored to a general user (not personalized)\n",
        "- Fact-based, but sensitive to nuance, caution, or best practices\n",
        "- Free from subjective judgment or emotional language\n",
        "- Respectful of varying conditions or assumptions\n",
        "- Aligned with the provided context; if not relevant, ignore the context\n",
        "\n",
        "# {normal_context}\n",
        "# {step_back_context}\n",
        "\n",
        "# Original Question: {question}\n",
        "# Answer:\"\"\"\n",
        "\n",
        "#comparison\n",
        "comparisonprompt = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
        "You are responding to a query with the intent: COMPARISON.\n",
        "Your answer should be:\n",
        "- A neutral, side-by-side analysis of options or alternatives\n",
        "- Factually grounded—avoid personal recommendations unless one option is clearly superior based on evidence\n",
        "- Clearly structured with bullet points or short paragraphs\n",
        "- Helpful in illustrating pros and cons, similarities, and differences\n",
        "- Consistent with the context provided; ignore it if irrelevant\n",
        "\n",
        "# {normal_context}\n",
        "# {step_back_context}\n",
        "\n",
        "# Original Question: {question}\n",
        "# Answer:\n",
        "Option A:\n",
        "Option B: \"\"\"\n",
        "\n",
        "#general prompt\n",
        "generalprompt = \"\"\"You are an expert of world knowledge. I am going to ask you a question. Your response should be comprehensive and not contradicted with the following context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
        "You are responding to a query with the intent: GENERAL.\n",
        "Your answer should be:\n",
        "- Informative and contextually aware\n",
        "- Concise but flexible in length (aim for clarity)\n",
        "- Objective and based on verifiable information\n",
        "- Avoid speculation or personal opinion\n",
        "- Aligned with the provided context if relevant\n",
        "\n",
        "# {normal_context}\n",
        "# {step_back_context}\n",
        "\n",
        "# Original Question: {question}\n",
        "# Answer:\"\"\"\n"
      ],
      "metadata": {
        "id": "js-4zkKCNf7u"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(b) load prompt into a global variable"
      ],
      "metadata": {
        "id": "Gb1n-ufKVEYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableLambda\n",
        "\n",
        "intent_router = RunnableLambda(lambda x: {\n",
        "    \"DEFINE\": HuggingFaceChatRunnable(client, defineprompt, 0.0, 1024),\n",
        "    \"EXPLAIN\": HuggingFaceChatRunnable(client, explainprompt, 0.0, 1024),\n",
        "    \"PROCEDURE\": HuggingFaceChatRunnable(client, procedureprompt, 0.0, 1024),\n",
        "    \"ADVICE\": HuggingFaceChatRunnable(client, adviceprompt, 0.0, 1024),\n",
        "    \"COMPARISON\": HuggingFaceChatRunnable(client, comparisonprompt, 0.0, 1024),\n",
        "    \"GENERAL\": HuggingFaceChatRunnable(client, generalprompt, 0.0, 1024),\n",
        "}[x[\"intent\"].strip()]\n",
        ")"
      ],
      "metadata": {
        "id": "VwaqGKQZVnrV"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(c) Chain"
      ],
      "metadata": {
        "id": "2r3gaX9HPGMN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnableMap, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "chain = (\n",
        "    RunnableMap({\n",
        "        \"question\": lambda x: x[\"question\"],\n",
        "        \"step_back_question\": lambda x: x[\"question\"],\n",
        "        \"intent\": lambda x: router.invoke({\"question\": x[\"question\"]})\n",
        "    })\n",
        "    | RunnableLambda(lambda x: {\n",
        "        \"normal_context\": retriever.invoke(x[\"question\"]),\n",
        "        \"step_back_q\": stepback.invoke({\"intent\" : x[\"intent\"],\"question\": x[\"step_back_question\"]}),\n",
        "        \"question\": x[\"question\"],\n",
        "        \"intent\": next(iter(x[\"intent\"])) if isinstance(x[\"intent\"], set) else x[\"intent\"]\n",
        "    })\n",
        "    | RunnableLambda(lambda x: {\n",
        "        \"step_back_context\": retriever.invoke(x[\"step_back_q\"]),\n",
        "        \"normal_context\": x[\"normal_context\"],\n",
        "        \"question\": x[\"question\"],\n",
        "        \"intent\": x[\"intent\"]\n",
        "    })\n",
        "    | intent_router\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "QZcCABL5PExS"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 8: Running the Query"
      ],
      "metadata": {
        "id": "nnQdzYeSXkN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "question = input(\"Ask me anything! \\n\")\n",
        "\n",
        "# Generate the Response\n",
        "response = chain.invoke({\"question\": question})\n",
        "print(response)"
      ],
      "metadata": {
        "id": "bgR7DAHyXrHV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}